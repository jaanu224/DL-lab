{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11966530",
   "metadata": {},
   "source": [
    "# Module 3 — Program B: CNN Variants for Simple Object Detection (Synthetic MNIST Boxes)\n",
    "\n",
    "**Aim:** Build **two CNN variants** for multi‑task learning (digit classification + bounding‑box regression) and compare performance.  \n",
    "**Covers:** Deeper vs regular CNN backbones, padding/stride impact on localization, multi‑head loss (CE + SmoothL1/MSE), evaluation via **accuracy** and **IoU**.\n",
    "\n",
    "> Dataset: **Synthetic MNIST‑on‑Canvas** — each 64×64 image contains one MNIST digit placed at a random location with ground‑truth bbox.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e63e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "def make_canvas_set(x, y, n=12000, img_size=64, digit_size=20, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = np.zeros((n, img_size, img_size), dtype='float32')\n",
    "    cls = np.zeros((n,), dtype='int32')\n",
    "    bbox = np.zeros((n, 4), dtype='float32')  # x,y,w,h normalized [0,1]\n",
    "    for i in range(n):\n",
    "        idx = rng.integers(0, x.shape[0])\n",
    "        digit = tf.image.resize(x[idx][..., None].astype('float32'), (digit_size, digit_size)).numpy()[...,0]/255.0\n",
    "        H, W = img_size, img_size\n",
    "        h, w = digit.shape\n",
    "        top = rng.integers(0, H - h + 1)\n",
    "        left = rng.integers(0, W - w + 1)\n",
    "        X[i, top:top+h, left:left+w] = digit\n",
    "        cls[i] = y[idx]\n",
    "        # bbox as center x,y and width,height in [0,1]\n",
    "        cx = (left + w/2)/W; cy = (top + h/2)/H; bw = w/W; bh = h/H\n",
    "        bbox[i] = [cx, cy, bw, bh]\n",
    "    X = X[..., None]\n",
    "    return X, cls, bbox\n",
    "\n",
    "# Build train/val/test synthetic sets (fast demo sizes; increase for stronger results)\n",
    "Xtr, ctr, btr = make_canvas_set(x_train, y_train, n=12000)\n",
    "Xte, cte, bte = make_canvas_set(x_test,  y_test,  n=2000, seed=7)\n",
    "\n",
    "print('Train:', Xtr.shape, ctr.shape, btr.shape)\n",
    "print('Test:',  Xte.shape, cte.shape, bte.shape)\n",
    "\n",
    "# Quick visualization\n",
    "fig, ax = plt.subplots(1,3, figsize=(9,3))\n",
    "for i in range(3):\n",
    "    ax[i].imshow(Xtr[i,...,0], cmap='gray'); ax[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600bf3e0",
   "metadata": {},
   "source": [
    "## 1) Model Variants: Baseline vs Deeper (with BN/Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec724e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def head_multitask(x):\n",
    "    # classification head\n",
    "    cls = layers.Dense(10, activation='softmax', name='cls')(x)\n",
    "    # bbox head (cx, cy, w, h) in [0,1]\n",
    "    bbox = layers.Dense(4, activation='sigmoid', name='bbox')(x)\n",
    "    return cls, bbox\n",
    "\n",
    "def backbone_baseline(input_shape=(64,64,1)):\n",
    "    inp = layers.Input(input_shape)\n",
    "    x = layers.Conv2D(16, 3, padding='same', activation='relu')(inp)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    cls, bbox = head_multitask(x)\n",
    "    m = models.Model(inp, [cls, bbox], name='baseline')\n",
    "    return m\n",
    "\n",
    "def backbone_deeper(input_shape=(64,64,1)):\n",
    "    inp = layers.Input(input_shape)\n",
    "    x = layers.Conv2D(32, 3, padding='same', use_bias=False)(inp); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', use_bias=False)(x); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    cls, bbox = head_multitask(x)\n",
    "    m = models.Model(inp, [cls, bbox], name='deeper_bn_do')\n",
    "    return m\n",
    "\n",
    "def compile_multitask(model, lr=1e-3, bbox_loss='mse', lw_bbox=5.0):\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                  loss={'cls':'sparse_categorical_crossentropy', 'bbox': bbox_loss},\n",
    "                  loss_weights={'cls':1.0, 'bbox':lw_bbox},\n",
    "                  metrics={'cls':'accuracy'})\n",
    "    return model\n",
    "\n",
    "m1 = compile_multitask(backbone_baseline())\n",
    "m2 = compile_multitask(backbone_deeper())\n",
    "m1.summary(); m2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da813dad",
   "metadata": {},
   "source": [
    "## 2) Training & Evaluation (Accuracy + IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_boxes(b1, b2):\n",
    "    # b1, b2 in [cx, cy, w, h] normalized; convert to (x1,y1,x2,y2) then IoU\n",
    "    def to_xyxy(b):\n",
    "        cx, cy, w, h = b[...,0], b[...,1], b[...,2], b[...,3]\n",
    "        x1 = cx - w/2; y1 = cy - h/2; x2 = cx + w/2; y2 = cy + h/2\n",
    "        return x1, y1, x2, y2\n",
    "    x1a, y1a, x2a, y2a = to_xyxy(b1)\n",
    "    x1b, y1b, x2b, y2b = to_xyxy(b2)\n",
    "    xi1, yi1 = np.maximum(x1a, x1b), np.maximum(y1a, y1b)\n",
    "    xi2, yi2 = np.minimum(x2a, x2b), np.minimum(y2a, y2b)\n",
    "    inter = np.clip(xi2 - xi1, 0, 1) * np.clip(yi2 - yi1, 0, 1)\n",
    "    area_a = np.clip(x2a - x1a, 0, 1) * np.clip(y2a - y1a, 0, 1)\n",
    "    area_b = np.clip(x2b - x1b, 0, 1) * np.clip(y2b - y1b, 0, 1)\n",
    "    union = area_a + area_b - inter + 1e-9\n",
    "    return (inter / union)\n",
    "\n",
    "EPOCHS = 6\n",
    "BATCH = 128\n",
    "\n",
    "hist = {}\n",
    "for name, model in [('baseline', m1), ('deeper', m2)]:    \n",
    "    h = model.fit(Xtr, {'cls': ctr, 'bbox': btr},\n",
    "                  validation_split=0.1, epochs=EPOCHS, batch_size=BATCH, verbose=1)\n",
    "    hist[name] = h\n",
    "\n",
    "# Evaluate\n",
    "results = {}\n",
    "for name, model in [('baseline', m1), ('deeper', m2)]:\n",
    "    preds = model.predict(Xte, batch_size=256, verbose=0)\n",
    "    cls_pred = np.argmax(preds[0], axis=1)\n",
    "    bbox_pred = preds[1]\n",
    "    acc = (cls_pred == cte).mean()\n",
    "    miou = iou_boxes(bbox_pred, bte).mean()\n",
    "    results[name] = {'acc': float(acc), 'miou': float(miou)}\n",
    "\n",
    "print('Results (approx):', {k: {m: round(v,4) for m,v in d.items()} for k,d in results.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacfb0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation accuracy for both variants\n",
    "fig, ax = plt.subplots()\n",
    "for name, h in hist.items():\n",
    "    ax.plot(h.history['val_cls_accuracy'], label=f'{name} cls')\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Val Acc'); ax.set_title('Classification Accuracy (val)')\n",
    "ax.legend(); plt.show()\n",
    "\n",
    "# Bar chart of final metrics\n",
    "names = list(results.keys())\n",
    "accs = [results[n]['acc'] for n in names]\n",
    "mious= [results[n]['miou'] for n in names]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(np.arange(len(names))-0.15, accs, width=0.3, label='Acc')\n",
    "ax.bar(np.arange(len(names))+0.15, mious, width=0.3, label='mIoU')\n",
    "ax.set_xticks(np.arange(len(names))); ax.set_xticklabels(names)\n",
    "ax.set_title('Variant Comparison: Accuracy vs mIoU (test)')\n",
    "ax.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1352f3",
   "metadata": {},
   "source": [
    "### Result & Inference (to be written)\n",
    "- Compare **baseline vs deeper**: which hits higher **accuracy** and **IoU** and why?\n",
    "- Discuss how **stride/pooling** may affect localization quality.\n",
    "- Suggest one improvement (e.g., focal loss, anchor‑based boxes, data augmentation).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
